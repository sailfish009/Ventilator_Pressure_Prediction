{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e46da0e1",
   "metadata": {
    "papermill": {
     "duration": 0.013391,
     "end_time": "2021-10-31T22:56:43.725613",
     "exception": false,
     "start_time": "2021-10-31T22:56:43.712222",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORT LIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8666091d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T22:56:43.754674Z",
     "iopub.status.busy": "2021-10-31T22:56:43.753529Z",
     "iopub.status.idle": "2021-10-31T22:56:49.323360Z",
     "shell.execute_reply": "2021-10-31T22:56:49.322551Z",
     "shell.execute_reply.started": "2021-10-31T18:40:16.505483Z"
    },
    "papermill": {
     "duration": 5.585278,
     "end_time": "2021-10-31T22:56:49.323529",
     "exception": false,
     "start_time": "2021-10-31T22:56:43.738251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 22:56:45.186761: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n",
      "2021-10-31 22:56:45.186900: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.layers import Concatenate, Add, GRU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0ddb2ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T22:56:49.353909Z",
     "iopub.status.busy": "2021-10-31T22:56:49.353155Z",
     "iopub.status.idle": "2021-10-31T22:56:49.355858Z",
     "shell.execute_reply": "2021-10-31T22:56:49.355435Z",
     "shell.execute_reply.started": "2021-10-31T18:40:23.010037Z"
    },
    "papermill": {
     "duration": 0.019478,
     "end_time": "2021-10-31T22:56:49.355985",
     "exception": false,
     "start_time": "2021-10-31T22:56:49.336507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Modify according to the seeds you set\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b46b5a",
   "metadata": {
    "papermill": {
     "duration": 0.012003,
     "end_time": "2021-10-31T22:56:49.380847",
     "exception": false,
     "start_time": "2021-10-31T22:56:49.368844",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd0d8a71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T22:56:49.408500Z",
     "iopub.status.busy": "2021-10-31T22:56:49.407880Z",
     "iopub.status.idle": "2021-10-31T22:57:01.899847Z",
     "shell.execute_reply": "2021-10-31T22:57:01.898953Z",
     "shell.execute_reply.started": "2021-10-31T18:40:23.016626Z"
    },
    "papermill": {
     "duration": 12.506765,
     "end_time": "2021-10-31T22:57:01.899993",
     "exception": false,
     "start_time": "2021-10-31T22:56:49.393228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df: (6036000, 8)\n",
      "test_df: (4024000, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breath_id</th>\n",
       "      <th>R</th>\n",
       "      <th>C</th>\n",
       "      <th>time_step</th>\n",
       "      <th>u_in</th>\n",
       "      <th>u_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.031904</td>\n",
       "      <td>7.515046</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.063827</td>\n",
       "      <td>14.651675</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.095751</td>\n",
       "      <td>21.230610</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.127644</td>\n",
       "      <td>26.320956</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  breath_id  R   C  time_step       u_in  u_out\n",
       "0   1          0  5  20   0.000000   0.000000      0\n",
       "1   2          0  5  20   0.031904   7.515046      0\n",
       "2   3          0  5  20   0.063827  14.651675      0\n",
       "3   4          0  5  20   0.095751  21.230610      0\n",
       "4   5          0  5  20   0.127644  26.320956      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\n",
    "print(f\"train_df: {train_df.shape}\")\n",
    "train_df.head()\n",
    "\n",
    "test_df = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\n",
    "print(f\"test_df: {test_df.shape}\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a24d6605",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T22:57:01.936434Z",
     "iopub.status.busy": "2021-10-31T22:57:01.935427Z",
     "iopub.status.idle": "2021-10-31T22:57:02.009630Z",
     "shell.execute_reply": "2021-10-31T22:57:02.009000Z",
     "shell.execute_reply.started": "2021-10-31T18:40:37.609524Z"
    },
    "papermill": {
     "duration": 0.095995,
     "end_time": "2021-10-31T22:57:02.009769",
     "exception": false,
     "start_time": "2021-10-31T22:57:01.913774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_pressure = sorted(train_df.pressure.unique())\n",
    "PRESSURE_MIN = all_pressure[0].item()\n",
    "PRESSURE_MAX = all_pressure[-1].item()\n",
    "PRESSURE_STEP = ( all_pressure[1] - all_pressure[0] ).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6953f5ed",
   "metadata": {
    "papermill": {
     "duration": 0.013136,
     "end_time": "2021-10-31T22:57:02.036432",
     "exception": false,
     "start_time": "2021-10-31T22:57:02.023296",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c21f760d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T22:57:02.086825Z",
     "iopub.status.busy": "2021-10-31T22:57:02.085754Z",
     "iopub.status.idle": "2021-10-31T22:59:25.199698Z",
     "shell.execute_reply": "2021-10-31T22:59:25.200165Z",
     "shell.execute_reply.started": "2021-10-31T18:40:37.692887Z"
    },
    "papermill": {
     "duration": 143.150496,
     "end_time": "2021-10-31T22:59:25.200346",
     "exception": false,
     "start_time": "2021-10-31T22:57:02.049850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/arraylike.py:364: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_set(df): #CV 0.1579\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    df['noise'] = np.random.choice([0, PRESSURE_STEP, -PRESSURE_STEP], len(df))\n",
    "    \n",
    "    df['flow'] = np.sqrt(2*df['u_in'])\n",
    "    \n",
    "    df['u_in_log'] = np.log(df['u_in']).replace(-np.inf,0)\n",
    "        \n",
    "    #df['area'] = df['time_step'] * df['u_in']\n",
    "    #df['area'] = df.groupby('breath_id')['area'].cumsum()\n",
    "    df['state'] = np.array([1 if x>0 else 0 for x in df['u_in']]) - df['u_out']\n",
    "    \n",
    "    #df['exhale'] = df.groupby('breath_id')['u_out'].cumsum()\n",
    "        \n",
    "    df['delta_time'] = df.groupby('breath_id')['time_step'].diff().fillna(0)\n",
    "    df['delta_u_in'] = df.groupby(df['breath_id'])['u_in'].diff().fillna(0).reset_index(level=0,drop=True)     \n",
    "    df['delta_flow'] = df.groupby(df['breath_id'])['flow'].diff().fillna(0).reset_index(level=0,drop=True)          \n",
    "    \n",
    "    df['inhale_time'] = df['state'] *  df['delta_time'] * (1 - df['u_out'])\n",
    "    df['inhale_time'] = (df.groupby(df['breath_id'])['inhale_time']).cumsum()  * (1 - df['u_out'])\n",
    "\n",
    "    df['flow_1st_der'] = (df['delta_flow'] /df['delta_time']).fillna(0)\n",
    "    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n",
    "    df['flow_cumsum'] = (df['flow']).groupby(df['breath_id']).cumsum()\n",
    "    \n",
    "    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2).fillna(0).reset_index(level=0,drop=True)\n",
    "    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4).fillna(0).reset_index(level=0,drop=True)\n",
    "\n",
    "    df['u_in_lag-1'] = df.groupby('breath_id')['u_in'].shift(-1).fillna(0).reset_index(level=0,drop=True)\n",
    "    \n",
    "    df['u_in_dif2'] = df['u_in'] - df['u_in_lag2']\n",
    "    df['u_in_dif4'] = df['u_in'] - df['u_in_lag4']\n",
    "    df['u_in_dif-1'] = df['u_in'] - df['u_in_lag-1']\n",
    "    \n",
    "    df['volume_mean']= df['flow'] * df['delta_time']\n",
    "\n",
    "       \n",
    "    df['volume_in_cumsum']=df.groupby('breath_id')['volume_mean'].cumsum()     \n",
    "    df['volume_in_cumsum_reverse']=df.groupby(df['breath_id'])['volume_in_cumsum'].transform('max')  - df['volume_in_cumsum']\n",
    "        \n",
    "    df['_volume'] = df['volume_in_cumsum'] * (1 - df['u_out'])\n",
    "    df['tidal_volume']=df.groupby(df['breath_id'])['_volume'].transform('max')\n",
    "    \n",
    "    df['volume_part'] = (df['volume_mean']/df['volume_in_cumsum']).fillna(0)\n",
    "    df['volume_part'] = df.groupby('breath_id')['volume_part'].shift(-1).fillna(0).reset_index(level=0,drop=True)\n",
    "    \n",
    "    df['time_constant'] = df.groupby(df['breath_id'])['inhale_time'].transform('max')\n",
    "    df['V_dot'] = df['tidal_volume'] / df['time_constant']\n",
    "    \n",
    "\n",
    "    df['u_in_rol_q0.25'] = df.groupby(df['breath_id'])['u_in'].rolling(window=10, min_periods=1, center=True).quantile(0.25).reset_index(level=0,drop=True)\n",
    "    df['u_in_rol_q0.75'] = df.groupby(df['breath_id'])['u_in'].rolling(window=10, min_periods=1, center=True).quantile(0.75).reset_index(level=0,drop=True)\n",
    "\n",
    "    \n",
    "    df['dP_on_R'] = df['flow'] * df['R']/1000 \n",
    "    df['lung_expand'] = df['dP_on_R'] * df['C'] \n",
    "    df['dP_on_C'] = df['flow'] * df['delta_time'] * 1000 / df['C'] \n",
    "    df['dP_on_C_cumsum'] = df.groupby('breath_id')['dP_on_C'].cumsum()   \n",
    "    \n",
    "    df['RC'] = df['R'].astype(str) + df['C'].astype(str)\n",
    "    df['R'] = df['R'].astype(str)\n",
    "    df['C'] = df['C'].astype(str)\n",
    "    df = pd.get_dummies(df)\n",
    "\n",
    "    df['u_in_1st_order_grad'] = np.stack(df.groupby(df['breath_id'])['u_in'].apply(np.gradient).values).reshape(len(df),)\n",
    "    \n",
    "\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train = prepare_set(train_df)\n",
    "test = prepare_set(test_df)\n",
    "\n",
    "del train_df, test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5b80c23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T22:59:25.230880Z",
     "iopub.status.busy": "2021-10-31T22:59:25.230309Z",
     "iopub.status.idle": "2021-10-31T22:59:26.513427Z",
     "shell.execute_reply": "2021-10-31T22:59:26.513937Z",
     "shell.execute_reply.started": "2021-10-31T18:43:47.265000Z"
    },
    "papermill": {
     "duration": 1.300245,
     "end_time": "2021-10-31T22:59:26.514110",
     "exception": false,
     "start_time": "2021-10-31T22:59:25.213865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (6036000, 50)\n"
     ]
    }
   ],
   "source": [
    "targets = train[['pressure']].to_numpy().reshape(-1, 80)\n",
    "u_outs = train[['u_out']].to_numpy().reshape(-1, 80)\n",
    "\n",
    "train.drop(['pressure', 'id', 'breath_id'], axis = 1, inplace = True)\n",
    "test = test.drop(['id', 'breath_id'], axis = 1)\n",
    "\n",
    "print(f\"train: {train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53c09836",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T22:59:26.545167Z",
     "iopub.status.busy": "2021-10-31T22:59:26.544530Z",
     "iopub.status.idle": "2021-10-31T22:59:36.844994Z",
     "shell.execute_reply": "2021-10-31T22:59:36.844527Z",
     "shell.execute_reply.started": "2021-10-31T18:43:48.719919Z"
    },
    "papermill": {
     "duration": 10.316935,
     "end_time": "2021-10-31T22:59:36.845173",
     "exception": false,
     "start_time": "2021-10-31T22:59:26.528238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (75450, 80, 50) \n",
      " targets: (75450, 80)\n"
     ]
    }
   ],
   "source": [
    "scaler = RobustScaler()\n",
    "train = scaler.fit_transform(train)\n",
    "test = scaler.transform(test)\n",
    "\n",
    "train = train.reshape(-1, 80, train.shape[-1])\n",
    "test = test.reshape(-1, 80, train.shape[-1])\n",
    "\n",
    "print(f\"train: {train.shape} \\n targets: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a5f502b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T22:59:36.896378Z",
     "iopub.status.busy": "2021-10-31T22:59:36.895734Z",
     "iopub.status.idle": "2021-10-31T22:59:42.926401Z",
     "shell.execute_reply": "2021-10-31T22:59:42.926844Z",
     "shell.execute_reply.started": "2021-10-31T18:43:59.603463Z"
    },
    "papermill": {
     "duration": 6.067524,
     "end_time": "2021-10-31T22:59:42.927028",
     "exception": false,
     "start_time": "2021-10-31T22:59:36.859504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 22:59:36.882374: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-10-31 22:59:36.885750: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n",
      "2021-10-31 22:59:36.885791: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-10-31 22:59:36.885829: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ad1d2093a456): /proc/driver/nvidia/version does not exist\n",
      "2021-10-31 22:59:36.888932: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-31 22:59:36.890428: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-10-31 22:59:36.896490: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-10-31 22:59:36.920417: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n",
      "2021-10-31 22:59:36.920468: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30020}\n",
      "2021-10-31 22:59:36.944366: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n",
      "2021-10-31 22:59:36.944422: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30020}\n",
      "2021-10-31 22:59:36.945887: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:30020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU: grpc://10.0.0.2:8470\n",
      "Batch Size: 512\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "    BATCH_SIZE = strategy.num_replicas_in_sync * 64\n",
    "    print(\"Running on TPU:\", tpu.master())\n",
    "    print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "    \n",
    "except ValueError:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    BATCH_SIZE = 512\n",
    "    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n",
    "    print(f\"Batch Size: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbe51af5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T22:59:42.968716Z",
     "iopub.status.busy": "2021-10-31T22:59:42.968027Z",
     "iopub.status.idle": "2021-10-31T22:59:42.970979Z",
     "shell.execute_reply": "2021-10-31T22:59:42.970465Z",
     "shell.execute_reply.started": "2021-10-31T18:44:05.405259Z"
    },
    "papermill": {
     "duration": 0.029183,
     "end_time": "2021-10-31T22:59:42.971115",
     "exception": false,
     "start_time": "2021-10-31T22:59:42.941932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GBVPP_loss(y_true, y_pred, cols = 80):\n",
    "    u_out = y_true[:, cols: ]\n",
    "    y = y_true[:, :cols ]\n",
    "\n",
    "    w = 1 - u_out\n",
    "    mae = w * tf.abs(y - y_pred)\n",
    "    return tf.reduce_sum(mae, axis=-1) / tf.reduce_sum(w, axis=-1)\n",
    "   \n",
    "def get_model():  \n",
    "    x_input = keras.Input(shape=(train.shape[-2:]))\n",
    "    \n",
    "    x1 = layers.Bidirectional(layers.LSTM(units=768, return_sequences=True))(x_input)\n",
    "    x2 = layers.Bidirectional(layers.LSTM(units=512, return_sequences=True))(x1)\n",
    "    x3 = layers.Bidirectional(layers.LSTM(units=384, return_sequences=True))(x2)\n",
    "    x4 = layers.Bidirectional(layers.LSTM(units=256, return_sequences=True))(x3)\n",
    "    x5 = layers.Bidirectional(layers.LSTM(units=128, return_sequences=True))(x4)\n",
    "    \n",
    "    z2 = layers.Bidirectional(layers.GRU(units=384, return_sequences=True))(x2)\n",
    "    \n",
    "    z31 = layers.Multiply()([x3, z2])\n",
    "    z31 = layers.BatchNormalization()(z31)\n",
    "    z3 = layers.Bidirectional(layers.GRU(units=256, return_sequences=True))(z31)\n",
    "    \n",
    "    z41 = layers.Multiply()([x4, z3])\n",
    "    z41 = layers.BatchNormalization()(z41)\n",
    "    z4 = layers.Bidirectional(layers.GRU(units=128, return_sequences=True))(z41)\n",
    "    \n",
    "    z51 = layers.Multiply()([x5, z4])\n",
    "    z51 = layers.BatchNormalization()(z51)\n",
    "    z5 = layers.Bidirectional(layers.GRU(units=64, return_sequences=True))(z51)\n",
    "    \n",
    "    x = layers.Concatenate(axis=2)([x5, z2, z3, z4, z5])\n",
    "    \n",
    "    x = layers.Dense(units=128, activation='selu')(x)\n",
    "    \n",
    "    x_output = layers.Dense(units=1)(x)\n",
    "    \n",
    "    model = keras.Model(inputs=x_input, outputs=x_output)\n",
    "    \n",
    "    model.compile(optimizer = \"adam\", \n",
    "                  #loss = \"mae\",\n",
    "                  loss=GBVPP_loss,\n",
    "                 #sample_weight_mode=\"temporal\",\n",
    "                 )\n",
    "    \n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f1a834b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T22:59:43.164895Z",
     "iopub.status.busy": "2021-10-31T22:59:43.163879Z",
     "iopub.status.idle": "2021-10-31T22:59:43.168778Z",
     "shell.execute_reply": "2021-10-31T22:59:43.168174Z",
     "shell.execute_reply.started": "2021-10-31T19:42:45.031054Z"
    },
    "papermill": {
     "duration": 0.182926,
     "end_time": "2021-10-31T22:59:43.168913",
     "exception": false,
     "start_time": "2021-10-31T22:59:42.985987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff46b17d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T22:59:43.213385Z",
     "iopub.status.busy": "2021-10-31T22:59:43.212686Z",
     "iopub.status.idle": "2021-10-31T22:59:43.215915Z",
     "shell.execute_reply": "2021-10-31T22:59:43.215388Z",
     "shell.execute_reply.started": "2021-10-31T19:42:42.748124Z"
    },
    "papermill": {
     "duration": 0.023803,
     "end_time": "2021-10-31T22:59:43.216048",
     "exception": false,
     "start_time": "2021-10-31T22:59:43.192245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ecdd358",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T22:59:43.256664Z",
     "iopub.status.busy": "2021-10-31T22:59:43.256079Z",
     "iopub.status.idle": "2021-10-31T22:59:49.118891Z",
     "shell.execute_reply": "2021-10-31T22:59:49.119431Z"
    },
    "papermill": {
     "duration": 5.883357,
     "end_time": "2021-10-31T22:59:49.119598",
     "exception": false,
     "start_time": "2021-10-31T22:59:43.236241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1667: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\n",
    "train_preds = train_df[['id', 'breath_id', 'pressure']]\n",
    "train_preds.loc[:, 'modified_breath_id'] = [i for i in range(len(train)) for _ in range(80)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90d7e5be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T22:59:49.160976Z",
     "iopub.status.busy": "2021-10-31T22:59:49.160320Z",
     "iopub.status.idle": "2021-11-01T03:17:54.007080Z",
     "shell.execute_reply": "2021-11-01T03:17:54.010425Z"
    },
    "papermill": {
     "duration": 15484.875716,
     "end_time": "2021-11-01T03:17:54.011443",
     "exception": false,
     "start_time": "2021-10-31T22:59:49.135727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 23:00:21.828149: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1086480000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "266/266 [==============================] - 81s 199ms/step - loss: 0.1450 - val_loss: 0.2217\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.22174, saving model to best_valid_fold_1.hdf5\n",
      "Epoch 2/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1500 - val_loss: 0.2347\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.22174\n",
      "Epoch 3/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1474 - val_loss: 0.2184\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.22174 to 0.21839, saving model to best_valid_fold_1.hdf5\n",
      "Epoch 4/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1479 - val_loss: 0.2452\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.21839\n",
      "Epoch 5/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1476 - val_loss: 0.1985\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.21839 to 0.19852, saving model to best_valid_fold_1.hdf5\n",
      "Epoch 6/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1444 - val_loss: 0.1948\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.19852 to 0.19475, saving model to best_valid_fold_1.hdf5\n",
      "Epoch 7/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1443 - val_loss: 0.1868\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.19475 to 0.18681, saving model to best_valid_fold_1.hdf5\n",
      "Epoch 8/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.1425 - val_loss: 0.2021\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.18681\n",
      "Epoch 9/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1423 - val_loss: 0.1940\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.18681\n",
      "Epoch 10/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.1427 - val_loss: 0.1981\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0004899999825283885.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.18681\n",
      "Epoch 11/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0980 - val_loss: 0.1936\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.18681\n",
      "Epoch 12/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0984 - val_loss: 0.1586\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.18681 to 0.15863, saving model to best_valid_fold_1.hdf5\n",
      "Epoch 13/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0968 - val_loss: 0.1873\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.15863\n",
      "Epoch 14/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0984 - val_loss: 0.1704\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.15863\n",
      "Epoch 15/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0973 - val_loss: 0.1897\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.15863\n",
      "Epoch 16/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0690 - val_loss: 0.1651\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.15863\n",
      "Epoch 17/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0678 - val_loss: 0.1562\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.15863 to 0.15621, saving model to best_valid_fold_1.hdf5\n",
      "Epoch 18/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0679 - val_loss: 0.1623\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.15621\n",
      "Epoch 19/40\n",
      "266/266 [==============================] - 37s 138ms/step - loss: 0.0679 - val_loss: 0.1544\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.15621 to 0.15438, saving model to best_valid_fold_1.hdf5\n",
      "Epoch 20/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0672 - val_loss: 0.1569\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.15438\n",
      "Epoch 21/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0675 - val_loss: 0.1579\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.15438\n",
      "Epoch 22/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0677 - val_loss: 0.1581\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.15438\n",
      "Epoch 23/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0476 - val_loss: 0.1580\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.15438\n",
      "Epoch 24/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0482 - val_loss: 0.1487\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.15438 to 0.14874, saving model to best_valid_fold_1.hdf5\n",
      "Epoch 25/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0475 - val_loss: 0.1543\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.14874\n",
      "Epoch 26/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0475 - val_loss: 0.1492\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.14874\n",
      "Epoch 27/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0477 - val_loss: 0.1488\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.14874\n",
      "Epoch 28/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0340 - val_loss: 0.1465\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.14874 to 0.14652, saving model to best_valid_fold_1.hdf5\n",
      "Epoch 29/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0342 - val_loss: 0.1466\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.14652\n",
      "Epoch 30/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0343 - val_loss: 0.1472\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.14652\n",
      "Epoch 31/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0344 - val_loss: 0.1498\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.14652\n",
      "Epoch 32/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0261 - val_loss: 0.1460\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.14652 to 0.14597, saving model to best_valid_fold_1.hdf5\n",
      "Epoch 33/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0258 - val_loss: 0.1459\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.14597 to 0.14591, saving model to best_valid_fold_1.hdf5\n",
      "Epoch 34/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0262 - val_loss: 0.1458\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.14591 to 0.14583, saving model to best_valid_fold_1.hdf5\n",
      "Epoch 35/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0255 - val_loss: 0.1470\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.14583\n",
      "Epoch 36/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0262 - val_loss: 0.1460\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.14583\n",
      "Epoch 37/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0266 - val_loss: 0.1460\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 8.235429777414538e-05.\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.14583\n",
      "Epoch 38/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0242 - val_loss: 0.1459\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.14583\n",
      "Epoch 39/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0240 - val_loss: 0.1458\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.14583 to 0.14583, saving model to best_valid_fold_1.hdf5\n",
      "Epoch 40/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0242 - val_loss: 0.1458\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 5.76480058953166e-05.\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.14583 to 0.14582, saving model to best_valid_fold_1.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1835: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-1 | OOF Score: 7.193707065321711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 23:25:32.089062: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 804800000 exceeds 10% of free system memory.\n",
      "2021-10-31 23:26:02.733839: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1086480000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "266/266 [==============================] - 82s 198ms/step - loss: 0.1491 - val_loss: 0.2273\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.22731, saving model to best_valid_fold_2.hdf5\n",
      "Epoch 2/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1535 - val_loss: 0.2021\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.22731 to 0.20208, saving model to best_valid_fold_2.hdf5\n",
      "Epoch 3/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1511 - val_loss: 0.1801\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.20208 to 0.18015, saving model to best_valid_fold_2.hdf5\n",
      "Epoch 4/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1515 - val_loss: 0.2563\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.18015\n",
      "Epoch 5/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1511 - val_loss: 0.2090\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.18015\n",
      "Epoch 6/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1498 - val_loss: 0.1999\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0004899999825283885.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.18015\n",
      "Epoch 7/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1046 - val_loss: 0.2059\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.18015\n",
      "Epoch 8/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1038 - val_loss: 0.1772\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.18015 to 0.17717, saving model to best_valid_fold_2.hdf5\n",
      "Epoch 9/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.1031 - val_loss: 0.1758\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.17717 to 0.17576, saving model to best_valid_fold_2.hdf5\n",
      "Epoch 10/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1030 - val_loss: 0.1868\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.17576\n",
      "Epoch 11/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1028 - val_loss: 0.1836\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.17576\n",
      "Epoch 12/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1026 - val_loss: 0.1778\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.17576\n",
      "Epoch 13/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0710 - val_loss: 0.1612\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.17576 to 0.16123, saving model to best_valid_fold_2.hdf5\n",
      "Epoch 14/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0705 - val_loss: 0.1638\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.16123\n",
      "Epoch 15/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0709 - val_loss: 0.1665\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.16123\n",
      "Epoch 16/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0709 - val_loss: 0.1691\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.16123\n",
      "Epoch 17/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0495 - val_loss: 0.1550\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.16123 to 0.15499, saving model to best_valid_fold_2.hdf5\n",
      "Epoch 18/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0495 - val_loss: 0.1580\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.15499\n",
      "Epoch 19/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0493 - val_loss: 0.1561\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.15499\n",
      "Epoch 20/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0496 - val_loss: 0.1532\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.15499 to 0.15317, saving model to best_valid_fold_2.hdf5\n",
      "Epoch 21/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0493 - val_loss: 0.1532\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.15317\n",
      "Epoch 22/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0492 - val_loss: 0.1546\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.15317\n",
      "Epoch 23/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0497 - val_loss: 0.1536\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.15317\n",
      "Epoch 24/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0352 - val_loss: 0.1506\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.15317 to 0.15056, saving model to best_valid_fold_2.hdf5\n",
      "Epoch 25/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0354 - val_loss: 0.1527\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.15056\n",
      "Epoch 26/40\n",
      "266/266 [==============================] - 37s 138ms/step - loss: 0.0359 - val_loss: 0.1523\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.15056\n",
      "Epoch 27/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0358 - val_loss: 0.1508\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.15056\n",
      "Epoch 28/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0278 - val_loss: 0.1500\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.15056 to 0.14999, saving model to best_valid_fold_2.hdf5\n",
      "Epoch 29/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0272 - val_loss: 0.1500\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.14999 to 0.14998, saving model to best_valid_fold_2.hdf5\n",
      "Epoch 30/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0272 - val_loss: 0.1500\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.14998\n",
      "Epoch 31/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0273 - val_loss: 0.1501\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 8.235429777414538e-05.\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.14998\n",
      "Epoch 32/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0267 - val_loss: 0.1502\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.14998\n",
      "Epoch 33/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0267 - val_loss: 0.1499\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.14998 to 0.14993, saving model to best_valid_fold_2.hdf5\n",
      "Epoch 34/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0268 - val_loss: 0.1500\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 5.76480058953166e-05.\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.14993\n",
      "Epoch 35/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0267 - val_loss: 0.1499\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.14993\n",
      "Epoch 36/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0265 - val_loss: 0.1500\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.14993\n",
      "Epoch 37/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0265 - val_loss: 0.1499\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.14993 to 0.14988, saving model to best_valid_fold_2.hdf5\n",
      "Epoch 38/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0266 - val_loss: 0.1499\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.14988\n",
      "Epoch 39/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0266 - val_loss: 0.1500\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.14988\n",
      "Epoch 40/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0265 - val_loss: 0.1499\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 4.0353603617404586e-05.\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.14988 to 0.14988, saving model to best_valid_fold_2.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1835: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-2 | OOF Score: 8.801313538898173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 23:51:12.975142: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 804800000 exceeds 10% of free system memory.\n",
      "2021-10-31 23:51:45.971245: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1086480000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "266/266 [==============================] - 83s 199ms/step - loss: 0.1665 - val_loss: 0.2157\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.21572, saving model to best_valid_fold_3.hdf5\n",
      "Epoch 2/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1730 - val_loss: 0.2260\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.21572\n",
      "Epoch 3/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1721 - val_loss: 0.2116\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.21572 to 0.21164, saving model to best_valid_fold_3.hdf5\n",
      "Epoch 4/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1699 - val_loss: 0.2293\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.21164\n",
      "Epoch 5/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1688 - val_loss: 0.2923\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.21164\n",
      "Epoch 6/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1699 - val_loss: 0.2293\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0004899999825283885.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.21164\n",
      "Epoch 7/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1183 - val_loss: 0.1984\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.21164 to 0.19836, saving model to best_valid_fold_3.hdf5\n",
      "Epoch 8/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1167 - val_loss: 0.2061\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.19836\n",
      "Epoch 9/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1169 - val_loss: 0.2004\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.19836\n",
      "Epoch 10/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1157 - val_loss: 0.2077\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.19836\n",
      "Epoch 11/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0804 - val_loss: 0.1738\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.19836 to 0.17376, saving model to best_valid_fold_3.hdf5\n",
      "Epoch 12/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0809 - val_loss: 0.1728\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.17376 to 0.17283, saving model to best_valid_fold_3.hdf5\n",
      "Epoch 13/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0804 - val_loss: 0.1715\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.17283 to 0.17151, saving model to best_valid_fold_3.hdf5\n",
      "Epoch 14/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0803 - val_loss: 0.1750\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.17151\n",
      "Epoch 15/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0807 - val_loss: 0.1877\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.17151\n",
      "Epoch 16/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0801 - val_loss: 0.1683\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.17151 to 0.16835, saving model to best_valid_fold_3.hdf5\n",
      "Epoch 17/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0803 - val_loss: 0.1761\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.16835\n",
      "Epoch 18/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0802 - val_loss: 0.1661\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.16835 to 0.16614, saving model to best_valid_fold_3.hdf5\n",
      "Epoch 19/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0800 - val_loss: 0.1696\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.16614\n",
      "Epoch 20/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0798 - val_loss: 0.1718\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.16614\n",
      "Epoch 21/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0801 - val_loss: 0.1629\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.16614 to 0.16285, saving model to best_valid_fold_3.hdf5\n",
      "Epoch 22/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0801 - val_loss: 0.1616\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.16285 to 0.16163, saving model to best_valid_fold_3.hdf5\n",
      "Epoch 23/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0786 - val_loss: 0.1740\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.16163\n",
      "Epoch 24/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0800 - val_loss: 0.1653\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.16163\n",
      "Epoch 25/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0802 - val_loss: 0.1687\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.16163\n",
      "Epoch 26/40\n",
      "266/266 [==============================] - 37s 137ms/step - loss: 0.0561 - val_loss: 0.1562\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.16163 to 0.15620, saving model to best_valid_fold_3.hdf5\n",
      "Epoch 27/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0550 - val_loss: 0.1648\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.15620\n",
      "Epoch 28/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0558 - val_loss: 0.1630\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.15620\n",
      "Epoch 29/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0560 - val_loss: 0.1664\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.15620\n",
      "Epoch 30/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0393 - val_loss: 0.1509\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.15620 to 0.15091, saving model to best_valid_fold_3.hdf5\n",
      "Epoch 31/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0390 - val_loss: 0.1524\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.15091\n",
      "Epoch 32/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0391 - val_loss: 0.1527\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.15091\n",
      "Epoch 33/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0395 - val_loss: 0.1529\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.15091\n",
      "Epoch 34/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0286 - val_loss: 0.1498\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.15091 to 0.14978, saving model to best_valid_fold_3.hdf5\n",
      "Epoch 35/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0289 - val_loss: 0.1504\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.14978\n",
      "Epoch 36/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0284 - val_loss: 0.1497\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.14978 to 0.14975, saving model to best_valid_fold_3.hdf5\n",
      "Epoch 37/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0288 - val_loss: 0.1496\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.14975 to 0.14964, saving model to best_valid_fold_3.hdf5\n",
      "Epoch 38/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0285 - val_loss: 0.1504\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.14964\n",
      "Epoch 39/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0294 - val_loss: 0.1503\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.14964\n",
      "Epoch 40/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0292 - val_loss: 0.1500\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 8.235429777414538e-05.\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.14964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1835: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-3 | OOF Score: 8.375128162785286\n",
      "Epoch 1/40\n",
      "266/266 [==============================] - 84s 200ms/step - loss: 0.1518 - val_loss: 0.2008\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.20082, saving model to best_valid_fold_4.hdf5\n",
      "Epoch 2/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1549 - val_loss: 0.2557\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.20082\n",
      "Epoch 3/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1537 - val_loss: 0.1832\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.20082 to 0.18316, saving model to best_valid_fold_4.hdf5\n",
      "Epoch 4/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1520 - val_loss: 0.1959\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.18316\n",
      "Epoch 5/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1516 - val_loss: 0.2331\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.18316\n",
      "Epoch 6/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.1509 - val_loss: 0.2431\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0004899999825283885.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.18316\n",
      "Epoch 7/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1046 - val_loss: 0.1974\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.18316\n",
      "Epoch 8/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1042 - val_loss: 0.1716\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.18316 to 0.17159, saving model to best_valid_fold_4.hdf5\n",
      "Epoch 9/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1032 - val_loss: 0.1879\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.17159\n",
      "Epoch 10/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1038 - val_loss: 0.1911\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.17159\n",
      "Epoch 11/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1035 - val_loss: 0.1961\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.17159\n",
      "Epoch 12/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0719 - val_loss: 0.1636\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.17159 to 0.16360, saving model to best_valid_fold_4.hdf5\n",
      "Epoch 13/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0718 - val_loss: 0.1660\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.16360\n",
      "Epoch 14/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0721 - val_loss: 0.1605\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.16360 to 0.16052, saving model to best_valid_fold_4.hdf5\n",
      "Epoch 15/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0718 - val_loss: 0.1661\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.16052\n",
      "Epoch 16/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0721 - val_loss: 0.1594\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.16052 to 0.15939, saving model to best_valid_fold_4.hdf5\n",
      "Epoch 17/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0715 - val_loss: 0.1635\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.15939\n",
      "Epoch 18/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0711 - val_loss: 0.1762\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.15939\n",
      "Epoch 19/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0715 - val_loss: 0.1603\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.15939\n",
      "Epoch 20/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0497 - val_loss: 0.1573\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.15939 to 0.15730, saving model to best_valid_fold_4.hdf5\n",
      "Epoch 21/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0501 - val_loss: 0.1515\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.15730 to 0.15151, saving model to best_valid_fold_4.hdf5\n",
      "Epoch 22/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0495 - val_loss: 0.1525\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.15151\n",
      "Epoch 23/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0497 - val_loss: 0.1577\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.15151\n",
      "Epoch 24/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0502 - val_loss: 0.1537\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.15151\n",
      "Epoch 25/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0358 - val_loss: 0.1522\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.15151\n",
      "Epoch 26/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0360 - val_loss: 0.1536\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.15151\n",
      "Epoch 27/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0358 - val_loss: 0.1502\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.15151 to 0.15018, saving model to best_valid_fold_4.hdf5\n",
      "Epoch 28/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0352 - val_loss: 0.1504\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.15018\n",
      "Epoch 29/40\n",
      "266/266 [==============================] - 37s 138ms/step - loss: 0.0358 - val_loss: 0.1507\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.15018\n",
      "Epoch 30/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0356 - val_loss: 0.1508\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.15018\n",
      "Epoch 31/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0266 - val_loss: 0.1496\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.15018 to 0.14961, saving model to best_valid_fold_4.hdf5\n",
      "Epoch 32/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0264 - val_loss: 0.1500\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.14961\n",
      "Epoch 33/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0269 - val_loss: 0.1495\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.14961 to 0.14950, saving model to best_valid_fold_4.hdf5\n",
      "Epoch 34/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0267 - val_loss: 0.1501\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.14950\n",
      "Epoch 35/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0269 - val_loss: 0.1497\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.14950\n",
      "Epoch 36/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0266 - val_loss: 0.1496\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 8.235429777414538e-05.\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.14950\n",
      "Epoch 37/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0246 - val_loss: 0.1495\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.14950 to 0.14947, saving model to best_valid_fold_4.hdf5\n",
      "Epoch 38/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0247 - val_loss: 0.1495\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.14947\n",
      "Epoch 39/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0246 - val_loss: 0.1495\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 5.76480058953166e-05.\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.14947\n",
      "Epoch 40/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0245 - val_loss: 0.1495\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.14947 to 0.14946, saving model to best_valid_fold_4.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1835: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-4 | OOF Score: 7.644542911058743\n",
      "Epoch 1/40\n",
      "266/266 [==============================] - 84s 201ms/step - loss: 0.1765 - val_loss: 0.2540\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.25403, saving model to best_valid_fold_5.hdf5\n",
      "Epoch 2/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1811 - val_loss: 0.1909\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.25403 to 0.19088, saving model to best_valid_fold_5.hdf5\n",
      "Epoch 3/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1788 - val_loss: 0.2291\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.19088\n",
      "Epoch 4/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1796 - val_loss: 0.2592\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.19088\n",
      "Epoch 5/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1780 - val_loss: 0.2397\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0004899999825283885.\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.19088\n",
      "Epoch 6/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1244 - val_loss: 0.1716\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.19088 to 0.17164, saving model to best_valid_fold_5.hdf5\n",
      "Epoch 7/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1216 - val_loss: 0.2103\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.17164\n",
      "Epoch 8/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1230 - val_loss: 0.2045\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.17164\n",
      "Epoch 9/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1221 - val_loss: 0.2093\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.17164\n",
      "Epoch 10/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0855 - val_loss: 0.1867\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.17164\n",
      "Epoch 11/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0851 - val_loss: 0.1772\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.17164\n",
      "Epoch 12/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0842 - val_loss: 0.1919\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.17164\n",
      "Epoch 13/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0598 - val_loss: 0.1634\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.17164 to 0.16340, saving model to best_valid_fold_5.hdf5\n",
      "Epoch 14/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0591 - val_loss: 0.1668\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.16340\n",
      "Epoch 15/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0591 - val_loss: 0.1727\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.16340\n",
      "Epoch 16/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0598 - val_loss: 0.1779\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.16340\n",
      "Epoch 17/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0424 - val_loss: 0.1645\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.16340\n",
      "Epoch 18/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0424 - val_loss: 0.1586\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.16340 to 0.15861, saving model to best_valid_fold_5.hdf5\n",
      "Epoch 19/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0423 - val_loss: 0.1607\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.15861\n",
      "Epoch 20/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0424 - val_loss: 0.1614\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.15861\n",
      "Epoch 21/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0424 - val_loss: 0.1600\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.15861\n",
      "Epoch 22/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0300 - val_loss: 0.1566\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.15861 to 0.15659, saving model to best_valid_fold_5.hdf5\n",
      "Epoch 23/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0302 - val_loss: 0.1570\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.15659\n",
      "Epoch 24/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0304 - val_loss: 0.1596\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.15659\n",
      "Epoch 25/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0303 - val_loss: 0.1570\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 8.235429777414538e-05.\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.15659\n",
      "Epoch 26/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0229 - val_loss: 0.1563\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.15659 to 0.15632, saving model to best_valid_fold_5.hdf5\n",
      "Epoch 27/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0225 - val_loss: 0.1563\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.15632\n",
      "Epoch 28/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0223 - val_loss: 0.1566\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.15632\n",
      "Epoch 29/40\n",
      "266/266 [==============================] - 37s 138ms/step - loss: 0.0229 - val_loss: 0.1561\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.15632 to 0.15610, saving model to best_valid_fold_5.hdf5\n",
      "Epoch 30/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0229 - val_loss: 0.1562\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.15610\n",
      "Epoch 31/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0228 - val_loss: 0.1561\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.15610\n",
      "Epoch 32/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0228 - val_loss: 0.1561\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 5.76480058953166e-05.\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.15610 to 0.15607, saving model to best_valid_fold_5.hdf5\n",
      "Epoch 33/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0209 - val_loss: 0.1561\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.15607\n",
      "Epoch 34/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0210 - val_loss: 0.1564\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.15607\n",
      "Epoch 35/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0209 - val_loss: 0.1561\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 4.0353603617404586e-05.\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.15607\n",
      "Epoch 36/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0208 - val_loss: 0.1561\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.15607\n",
      "Epoch 37/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0208 - val_loss: 0.1561\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.15607\n",
      "Epoch 38/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0210 - val_loss: 0.1561\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 2.8247522277524694e-05.\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.15607\n",
      "Epoch 39/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0209 - val_loss: 0.1561\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.15607\n",
      "Epoch 40/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0209 - val_loss: 0.1561\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.15607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1835: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-5 | OOF Score: 6.674725214327795\n",
      "Epoch 1/40\n",
      "266/266 [==============================] - 83s 200ms/step - loss: 0.1548 - val_loss: 0.2117\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.21167, saving model to best_valid_fold_6.hdf5\n",
      "Epoch 2/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1577 - val_loss: 0.2038\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.21167 to 0.20383, saving model to best_valid_fold_6.hdf5\n",
      "Epoch 3/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1569 - val_loss: 0.2124\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.20383\n",
      "Epoch 4/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1540 - val_loss: 0.2674\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.20383\n",
      "Epoch 5/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1551 - val_loss: 0.2514\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0004899999825283885.\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.20383\n",
      "Epoch 6/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1083 - val_loss: 0.1923\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.20383 to 0.19230, saving model to best_valid_fold_6.hdf5\n",
      "Epoch 7/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1075 - val_loss: 0.2249\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.19230\n",
      "Epoch 8/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1077 - val_loss: 0.1952\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.19230\n",
      "Epoch 9/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1058 - val_loss: 0.1926\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.19230\n",
      "Epoch 10/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0749 - val_loss: 0.1726\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.19230 to 0.17260, saving model to best_valid_fold_6.hdf5\n",
      "Epoch 11/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0741 - val_loss: 0.1723\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.17260 to 0.17232, saving model to best_valid_fold_6.hdf5\n",
      "Epoch 12/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0742 - val_loss: 0.1611\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.17232 to 0.16107, saving model to best_valid_fold_6.hdf5\n",
      "Epoch 13/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0737 - val_loss: 0.1638\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.16107\n",
      "Epoch 14/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0739 - val_loss: 0.1699\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.16107\n",
      "Epoch 15/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0740 - val_loss: 0.1580\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.16107 to 0.15803, saving model to best_valid_fold_6.hdf5\n",
      "Epoch 16/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0735 - val_loss: 0.1633\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.15803\n",
      "Epoch 17/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0733 - val_loss: 0.1649\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.15803\n",
      "Epoch 18/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0734 - val_loss: 0.1678\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.15803\n",
      "Epoch 19/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0515 - val_loss: 0.1556\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.15803 to 0.15556, saving model to best_valid_fold_6.hdf5\n",
      "Epoch 20/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0513 - val_loss: 0.1561\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.15556\n",
      "Epoch 21/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0512 - val_loss: 0.1606\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.15556\n",
      "Epoch 22/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0517 - val_loss: 0.1586\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.15556\n",
      "Epoch 23/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0370 - val_loss: 0.1482\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.15556 to 0.14822, saving model to best_valid_fold_6.hdf5\n",
      "Epoch 24/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0359 - val_loss: 0.1517\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.14822\n",
      "Epoch 25/40\n",
      "266/266 [==============================] - 37s 138ms/step - loss: 0.0365 - val_loss: 0.1495\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.14822\n",
      "Epoch 26/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0366 - val_loss: 0.1490\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.14822\n",
      "Epoch 27/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0267 - val_loss: 0.1483\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.14822\n",
      "Epoch 28/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0273 - val_loss: 0.1477\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.14822 to 0.14772, saving model to best_valid_fold_6.hdf5\n",
      "Epoch 29/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0269 - val_loss: 0.1477\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.14772 to 0.14767, saving model to best_valid_fold_6.hdf5\n",
      "Epoch 30/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0266 - val_loss: 0.1478\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.14767\n",
      "Epoch 31/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0269 - val_loss: 0.1483\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 8.235429777414538e-05.\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.14767\n",
      "Epoch 32/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0249 - val_loss: 0.1477\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.14767\n",
      "Epoch 33/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0248 - val_loss: 0.1477\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.14767\n",
      "Epoch 34/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0248 - val_loss: 0.1476\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 5.76480058953166e-05.\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.14767 to 0.14763, saving model to best_valid_fold_6.hdf5\n",
      "Epoch 35/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0247 - val_loss: 0.1477\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.14763\n",
      "Epoch 36/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0248 - val_loss: 0.1477\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.14763\n",
      "Epoch 37/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0247 - val_loss: 0.1477\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 4.0353603617404586e-05.\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.14763\n",
      "Epoch 38/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0247 - val_loss: 0.1476\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.14763\n",
      "Epoch 39/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0248 - val_loss: 0.1477\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.14763\n",
      "Epoch 40/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0250 - val_loss: 0.1477\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 2.8247522277524694e-05.\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.14763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1835: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-6 | OOF Score: 7.6059300719509215\n",
      "Epoch 1/40\n",
      "266/266 [==============================] - 83s 200ms/step - loss: 0.1373 - val_loss: 0.2107\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.21068, saving model to best_valid_fold_7.hdf5\n",
      "Epoch 2/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1410 - val_loss: 0.1932\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.21068 to 0.19319, saving model to best_valid_fold_7.hdf5\n",
      "Epoch 3/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1398 - val_loss: 0.2143\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.19319\n",
      "Epoch 4/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1389 - val_loss: 0.2196\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.19319\n",
      "Epoch 5/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1392 - val_loss: 0.2497\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0004899999825283885.\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.19319\n",
      "Epoch 6/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0957 - val_loss: 0.1778\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.19319 to 0.17778, saving model to best_valid_fold_7.hdf5\n",
      "Epoch 7/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0959 - val_loss: 0.1785\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.17778\n",
      "Epoch 8/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0956 - val_loss: 0.1738\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.17778 to 0.17381, saving model to best_valid_fold_7.hdf5\n",
      "Epoch 9/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0950 - val_loss: 0.1887\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.17381\n",
      "Epoch 10/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0953 - val_loss: 0.1857\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.17381\n",
      "Epoch 11/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0957 - val_loss: 0.1879\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.17381\n",
      "Epoch 12/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0660 - val_loss: 0.1674\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.17381 to 0.16739, saving model to best_valid_fold_7.hdf5\n",
      "Epoch 13/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0658 - val_loss: 0.1678\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.16739\n",
      "Epoch 14/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0659 - val_loss: 0.1715\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.16739\n",
      "Epoch 15/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0661 - val_loss: 0.1666\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.16739 to 0.16663, saving model to best_valid_fold_7.hdf5\n",
      "Epoch 16/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0656 - val_loss: 0.1600\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.16663 to 0.15995, saving model to best_valid_fold_7.hdf5\n",
      "Epoch 17/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0654 - val_loss: 0.1736\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.15995\n",
      "Epoch 18/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0655 - val_loss: 0.1727\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.15995\n",
      "Epoch 19/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0658 - val_loss: 0.1627\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.15995\n",
      "Epoch 20/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0455 - val_loss: 0.1541\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.15995 to 0.15412, saving model to best_valid_fold_7.hdf5\n",
      "Epoch 21/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0455 - val_loss: 0.1591\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.15412\n",
      "Epoch 22/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0458 - val_loss: 0.1563\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.15412\n",
      "Epoch 23/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0454 - val_loss: 0.1554\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.15412\n",
      "Epoch 24/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0328 - val_loss: 0.1525\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.15412 to 0.15253, saving model to best_valid_fold_7.hdf5\n",
      "Epoch 25/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0329 - val_loss: 0.1525\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.15253 to 0.15249, saving model to best_valid_fold_7.hdf5\n",
      "Epoch 26/40\n",
      "266/266 [==============================] - 37s 138ms/step - loss: 0.0331 - val_loss: 0.1511\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.15249 to 0.15111, saving model to best_valid_fold_7.hdf5\n",
      "Epoch 27/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0324 - val_loss: 0.1526\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.15111\n",
      "Epoch 28/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0330 - val_loss: 0.1528\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.15111\n",
      "Epoch 29/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0327 - val_loss: 0.1522\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.15111\n",
      "Epoch 30/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0261 - val_loss: 0.1517\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.15111\n",
      "Epoch 31/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0258 - val_loss: 0.1513\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.15111\n",
      "Epoch 32/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0257 - val_loss: 0.1510\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.15111 to 0.15096, saving model to best_valid_fold_7.hdf5\n",
      "Epoch 33/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0258 - val_loss: 0.1512\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.15096\n",
      "Epoch 34/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0258 - val_loss: 0.1510\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.15096\n",
      "Epoch 35/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0257 - val_loss: 0.1511\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 8.235429777414538e-05.\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.15096\n",
      "Epoch 36/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0253 - val_loss: 0.1510\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.15096\n",
      "Epoch 37/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0253 - val_loss: 0.1509\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.15096 to 0.15091, saving model to best_valid_fold_7.hdf5\n",
      "Epoch 38/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0251 - val_loss: 0.1509\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 5.76480058953166e-05.\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.15091\n",
      "Epoch 39/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0252 - val_loss: 0.1509\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.15091 to 0.15090, saving model to best_valid_fold_7.hdf5\n",
      "Epoch 40/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0252 - val_loss: 0.1509\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.15090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1835: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-7 | OOF Score: 8.46230681171887\n",
      "Epoch 1/40\n",
      "266/266 [==============================] - 84s 199ms/step - loss: 0.1670 - val_loss: 0.2299\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.22987, saving model to best_valid_fold_8.hdf5\n",
      "Epoch 2/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1698 - val_loss: 0.2722\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.22987\n",
      "Epoch 3/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1702 - val_loss: 0.2885\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.22987\n",
      "Epoch 4/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1693 - val_loss: 0.2434\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0004899999825283885.\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.22987\n",
      "Epoch 5/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1182 - val_loss: 0.1903\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.22987 to 0.19032, saving model to best_valid_fold_8.hdf5\n",
      "Epoch 6/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1167 - val_loss: 0.1688\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.19032 to 0.16878, saving model to best_valid_fold_8.hdf5\n",
      "Epoch 7/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1147 - val_loss: 0.1789\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.16878\n",
      "Epoch 8/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1143 - val_loss: 0.1845\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.16878\n",
      "Epoch 9/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1149 - val_loss: 0.1948\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.16878\n",
      "Epoch 10/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0813 - val_loss: 0.1605\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.16878 to 0.16049, saving model to best_valid_fold_8.hdf5\n",
      "Epoch 11/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0798 - val_loss: 0.1655\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.16049\n",
      "Epoch 12/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0805 - val_loss: 0.1724\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.16049\n",
      "Epoch 13/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0806 - val_loss: 0.1677\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.16049\n",
      "Epoch 14/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0561 - val_loss: 0.1537\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.16049 to 0.15366, saving model to best_valid_fold_8.hdf5\n",
      "Epoch 15/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0559 - val_loss: 0.1520\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.15366 to 0.15204, saving model to best_valid_fold_8.hdf5\n",
      "Epoch 16/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0557 - val_loss: 0.1588\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.15204\n",
      "Epoch 17/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0560 - val_loss: 0.1590\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.15204\n",
      "Epoch 18/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0562 - val_loss: 0.1575\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.15204\n",
      "Epoch 19/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0394 - val_loss: 0.1499\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.15204 to 0.14988, saving model to best_valid_fold_8.hdf5\n",
      "Epoch 20/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0395 - val_loss: 0.1492\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.14988 to 0.14919, saving model to best_valid_fold_8.hdf5\n",
      "Epoch 21/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0399 - val_loss: 0.1509\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.14919\n",
      "Epoch 22/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0399 - val_loss: 0.1488\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.14919 to 0.14880, saving model to best_valid_fold_8.hdf5\n",
      "Epoch 23/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0394 - val_loss: 0.1543\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.14880\n",
      "Epoch 24/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0401 - val_loss: 0.1493\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.14880\n",
      "Epoch 25/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0398 - val_loss: 0.1494\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.14880\n",
      "Epoch 26/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0292 - val_loss: 0.1490\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.14880\n",
      "Epoch 27/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0293 - val_loss: 0.1485\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.14880 to 0.14850, saving model to best_valid_fold_8.hdf5\n",
      "Epoch 28/40\n",
      "266/266 [==============================] - 37s 137ms/step - loss: 0.0288 - val_loss: 0.1480\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.14850 to 0.14803, saving model to best_valid_fold_8.hdf5\n",
      "Epoch 29/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0290 - val_loss: 0.1479\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.14803 to 0.14788, saving model to best_valid_fold_8.hdf5\n",
      "Epoch 30/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0288 - val_loss: 0.1482\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.14788\n",
      "Epoch 31/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0290 - val_loss: 0.1488\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.14788\n",
      "Epoch 32/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0294 - val_loss: 0.1481\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 8.235429777414538e-05.\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.14788\n",
      "Epoch 33/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0242 - val_loss: 0.1478\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.14788 to 0.14781, saving model to best_valid_fold_8.hdf5\n",
      "Epoch 34/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0241 - val_loss: 0.1481\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.14781\n",
      "Epoch 35/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0243 - val_loss: 0.1479\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 5.76480058953166e-05.\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.14781\n",
      "Epoch 36/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0240 - val_loss: 0.1478\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.14781\n",
      "Epoch 37/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0241 - val_loss: 0.1479\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.14781\n",
      "Epoch 38/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0241 - val_loss: 0.1478\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 4.0353603617404586e-05.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.14781 to 0.14779, saving model to best_valid_fold_8.hdf5\n",
      "Epoch 39/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0238 - val_loss: 0.1478\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.14779\n",
      "Epoch 40/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0240 - val_loss: 0.1478\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.14779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1835: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-8 | OOF Score: 6.8821359510187055\n",
      "Epoch 1/40\n",
      "266/266 [==============================] - 84s 199ms/step - loss: 0.1524 - val_loss: 0.2366\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.23660, saving model to best_valid_fold_9.hdf5\n",
      "Epoch 2/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1572 - val_loss: 0.2202\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.23660 to 0.22015, saving model to best_valid_fold_9.hdf5\n",
      "Epoch 3/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1564 - val_loss: 0.2276\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.22015\n",
      "Epoch 4/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1554 - val_loss: 0.2573\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.22015\n",
      "Epoch 5/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1552 - val_loss: 0.2420\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0004899999825283885.\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.22015\n",
      "Epoch 6/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1069 - val_loss: 0.1985\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.22015 to 0.19848, saving model to best_valid_fold_9.hdf5\n",
      "Epoch 7/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1075 - val_loss: 0.2071\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.19848\n",
      "Epoch 8/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1069 - val_loss: 0.1968\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.19848 to 0.19685, saving model to best_valid_fold_9.hdf5\n",
      "Epoch 9/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1068 - val_loss: 0.1739\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.19685 to 0.17388, saving model to best_valid_fold_9.hdf5\n",
      "Epoch 10/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1060 - val_loss: 0.1941\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.17388\n",
      "Epoch 11/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1057 - val_loss: 0.1812\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.17388\n",
      "Epoch 12/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1055 - val_loss: 0.1669\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.17388 to 0.16692, saving model to best_valid_fold_9.hdf5\n",
      "Epoch 13/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1048 - val_loss: 0.1929\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.16692\n",
      "Epoch 14/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1051 - val_loss: 0.1956\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.16692\n",
      "Epoch 15/40\n",
      "266/266 [==============================] - 36s 137ms/step - loss: 0.1049 - val_loss: 0.1982\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.16692\n",
      "Epoch 16/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0730 - val_loss: 0.1603\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.16692 to 0.16033, saving model to best_valid_fold_9.hdf5\n",
      "Epoch 17/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0725 - val_loss: 0.1792\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.16033\n",
      "Epoch 18/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0734 - val_loss: 0.1647\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.16033\n",
      "Epoch 19/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0732 - val_loss: 0.1589\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.16033 to 0.15894, saving model to best_valid_fold_9.hdf5\n",
      "Epoch 20/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0726 - val_loss: 0.1682\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.15894\n",
      "Epoch 21/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0727 - val_loss: 0.1649\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.15894\n",
      "Epoch 22/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0726 - val_loss: 0.1591\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.15894\n",
      "Epoch 23/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0506 - val_loss: 0.1540\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.15894 to 0.15402, saving model to best_valid_fold_9.hdf5\n",
      "Epoch 24/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0506 - val_loss: 0.1496\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.15402 to 0.14959, saving model to best_valid_fold_9.hdf5\n",
      "Epoch 25/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0505 - val_loss: 0.1504\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.14959\n",
      "Epoch 26/40\n",
      "266/266 [==============================] - 37s 137ms/step - loss: 0.0509 - val_loss: 0.1509\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.14959\n",
      "Epoch 27/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0507 - val_loss: 0.1543\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.14959\n",
      "Epoch 28/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0362 - val_loss: 0.1477\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.14959 to 0.14769, saving model to best_valid_fold_9.hdf5\n",
      "Epoch 29/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0360 - val_loss: 0.1457\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.14769 to 0.14574, saving model to best_valid_fold_9.hdf5\n",
      "Epoch 30/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0355 - val_loss: 0.1487\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.14574\n",
      "Epoch 31/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0359 - val_loss: 0.1467\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.14574\n",
      "Epoch 32/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0358 - val_loss: 0.1477\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.14574\n",
      "Epoch 33/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0267 - val_loss: 0.1455\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.14574 to 0.14547, saving model to best_valid_fold_9.hdf5\n",
      "Epoch 34/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0267 - val_loss: 0.1456\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.14547\n",
      "Epoch 35/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0267 - val_loss: 0.1454\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.14547 to 0.14544, saving model to best_valid_fold_9.hdf5\n",
      "Epoch 36/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0270 - val_loss: 0.1460\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 8.235429777414538e-05.\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.14544\n",
      "Epoch 37/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0240 - val_loss: 0.1453\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.14544 to 0.14527, saving model to best_valid_fold_9.hdf5\n",
      "Epoch 38/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0239 - val_loss: 0.1453\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.14527 to 0.14526, saving model to best_valid_fold_9.hdf5\n",
      "Epoch 39/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0240 - val_loss: 0.1453\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.14526\n",
      "Epoch 40/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0239 - val_loss: 0.1453\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 5.76480058953166e-05.\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.14526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1835: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-9 | OOF Score: 8.045731011693714\n",
      "Epoch 1/40\n",
      "266/266 [==============================] - 84s 201ms/step - loss: 0.1787 - val_loss: 0.2204\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.22043, saving model to best_valid_fold_10.hdf5\n",
      "Epoch 2/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1826 - val_loss: 0.2344\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.22043\n",
      "Epoch 3/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1815 - val_loss: 0.2511\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.22043\n",
      "Epoch 4/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1805 - val_loss: 0.2619\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0004899999825283885.\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.22043\n",
      "Epoch 5/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1255 - val_loss: 0.1779\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.22043 to 0.17792, saving model to best_valid_fold_10.hdf5\n",
      "Epoch 6/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.1246 - val_loss: 0.2289\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.17792\n",
      "Epoch 7/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.1254 - val_loss: 0.2208\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.17792\n",
      "Epoch 8/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.1238 - val_loss: 0.2343\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.17792\n",
      "Epoch 9/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0864 - val_loss: 0.1781\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.17792\n",
      "Epoch 10/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0865 - val_loss: 0.1785\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.17792\n",
      "Epoch 11/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0864 - val_loss: 0.1752\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.17792 to 0.17516, saving model to best_valid_fold_10.hdf5\n",
      "Epoch 12/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0861 - val_loss: 0.1736\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.17516 to 0.17361, saving model to best_valid_fold_10.hdf5\n",
      "Epoch 13/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0860 - val_loss: 0.1627\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.17361 to 0.16269, saving model to best_valid_fold_10.hdf5\n",
      "Epoch 14/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0852 - val_loss: 0.1867\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.16269\n",
      "Epoch 15/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0854 - val_loss: 0.1769\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.16269\n",
      "Epoch 16/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0864 - val_loss: 0.1877\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.16269\n",
      "Epoch 17/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0604 - val_loss: 0.1587\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.16269 to 0.15866, saving model to best_valid_fold_10.hdf5\n",
      "Epoch 18/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0601 - val_loss: 0.1621\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.15866\n",
      "Epoch 19/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0605 - val_loss: 0.1586\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.15866 to 0.15865, saving model to best_valid_fold_10.hdf5\n",
      "Epoch 20/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0603 - val_loss: 0.1687\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.15865\n",
      "Epoch 21/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0429 - val_loss: 0.1506\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.15865 to 0.15064, saving model to best_valid_fold_10.hdf5\n",
      "Epoch 22/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0424 - val_loss: 0.1512\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.15064\n",
      "Epoch 23/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0423 - val_loss: 0.1564\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.15064\n",
      "Epoch 24/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0429 - val_loss: 0.1563\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.15064\n",
      "Epoch 25/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0314 - val_loss: 0.1492\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.15064 to 0.14919, saving model to best_valid_fold_10.hdf5\n",
      "Epoch 26/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0310 - val_loss: 0.1480\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.14919 to 0.14804, saving model to best_valid_fold_10.hdf5\n",
      "Epoch 27/40\n",
      "266/266 [==============================] - 37s 138ms/step - loss: 0.0313 - val_loss: 0.1495\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.14804\n",
      "Epoch 28/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0314 - val_loss: 0.1479\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.14804 to 0.14786, saving model to best_valid_fold_10.hdf5\n",
      "Epoch 29/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0312 - val_loss: 0.1493\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.14786\n",
      "Epoch 30/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0315 - val_loss: 0.1485\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.14786\n",
      "Epoch 31/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0312 - val_loss: 0.1488\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 8.235429777414538e-05.\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.14786\n",
      "Epoch 32/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0242 - val_loss: 0.1479\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.14786\n",
      "Epoch 33/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0242 - val_loss: 0.1478\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.14786 to 0.14776, saving model to best_valid_fold_10.hdf5\n",
      "Epoch 34/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0242 - val_loss: 0.1484\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.14776\n",
      "Epoch 35/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0245 - val_loss: 0.1479\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.14776\n",
      "Epoch 36/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0245 - val_loss: 0.1478\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 5.76480058953166e-05.\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.14776\n",
      "Epoch 37/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0235 - val_loss: 0.1478\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.14776\n",
      "Epoch 38/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0233 - val_loss: 0.1479\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.14776\n",
      "Epoch 39/40\n",
      "266/266 [==============================] - 36s 135ms/step - loss: 0.0233 - val_loss: 0.1478\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 4.0353603617404586e-05.\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.14776 to 0.14776, saving model to best_valid_fold_10.hdf5\n",
      "Epoch 40/40\n",
      "266/266 [==============================] - 36s 136ms/step - loss: 0.0232 - val_loss: 0.1478\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.14776 to 0.14775, saving model to best_valid_fold_10.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1835: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-10 | OOF Score: 7.170678200161252\n"
     ]
    }
   ],
   "source": [
    "NUM_FOLD = 10\n",
    "EPOCH = 40\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    \n",
    "    VERBOSE = 0\n",
    "    test_preds = []\n",
    "    \n",
    "    kf = KFold(n_splits=NUM_FOLD, shuffle=True, random_state=100)\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n",
    "        X_train, X_valid = train[train_idx], train[test_idx]\n",
    "        y_train, y_valid = targets[train_idx], targets[test_idx]\n",
    "        u_out_train, u_out_valid = u_outs[train_idx], u_outs[test_idx]  \n",
    "        \n",
    "        model = get_model()\n",
    "        model_path = f'../input/gb-vpp-yet-another-lstm-colab/best_valid_fold_{fold+1}.hdf5' \n",
    "        model.load_weights(model_path)\n",
    "        \n",
    "        #keras.backend.set_value(model.optimizer.lr, 0.00007)\n",
    "        model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate=0.0007), loss=GBVPP_loss)\n",
    "        \n",
    "        plateau = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.7, patience=3, verbose=1, min_lr=1e-08)\n",
    "        estop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min',restore_best_weights=False)\n",
    "\n",
    "        checkpoint_filepath = f\"best_valid_fold_{fold+1}.hdf5\"\n",
    "        sv = keras.callbacks.ModelCheckpoint(\n",
    "            checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True,\n",
    "            save_weights_only=False, mode='auto', save_freq='epoch',\n",
    "            options=None\n",
    "        )\n",
    "        \n",
    "        \n",
    "        model.fit(X_train, np.append(y_train, u_out_train, axis =1),\n",
    "                  validation_data = (X_valid, np.append(y_valid, u_out_valid, axis =1)), epochs = EPOCH, \n",
    "                  batch_size = BATCH_SIZE, callbacks = [estop, plateau, sv],\n",
    "                  shuffle=True,\n",
    "                 )\n",
    "        \n",
    "        model.save(f\"end_of_fold_{fold+1}.hdf5\")\n",
    "            \n",
    "        y_true = y_valid.squeeze().reshape(-1, 1)\n",
    "        y_pred = model.predict(X_valid, batch_size=BATCH_SIZE).squeeze().reshape(-1, 1)\n",
    "        score = mean_absolute_error(y_true, y_pred)\n",
    "        train_preds.loc[train_preds.loc[:, 'modified_breath_id'].isin(test_idx), 'pressure'] = y_pred\n",
    "        print(f\"Fold-{fold+1} | OOF Score: {score}\")\n",
    "        \n",
    "        test_preds.append(model.predict(test, batch_size=BATCH_SIZE).squeeze().reshape(-1, 1).squeeze())\n",
    "        \n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "874a59bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-01T03:18:45.477893Z",
     "iopub.status.busy": "2021-11-01T03:18:45.477258Z",
     "iopub.status.idle": "2021-11-01T03:19:00.108350Z",
     "shell.execute_reply": "2021-11-01T03:19:00.108836Z",
     "shell.execute_reply.started": "2021-10-31T18:46:13.061704Z"
    },
    "papermill": {
     "duration": 39.323031,
     "end_time": "2021-11-01T03:19:00.109017",
     "exception": false,
     "start_time": "2021-11-01T03:18:20.785986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fea_names = ['id', 'pressure']\n",
    "train_preds[fea_names].to_csv('oof.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69823587",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-01T03:19:49.309749Z",
     "iopub.status.busy": "2021-11-01T03:19:49.308758Z",
     "iopub.status.idle": "2021-11-01T03:19:49.311404Z",
     "shell.execute_reply": "2021-11-01T03:19:49.310839Z",
     "shell.execute_reply.started": "2021-10-31T18:46:13.063282Z"
    },
    "papermill": {
     "duration": 24.573727,
     "end_time": "2021-11-01T03:19:49.311533",
     "exception": false,
     "start_time": "2021-11-01T03:19:24.737806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sub = pd.read_csv('../input/pressure-speed-and-weights-ltsm/submission.csv')\n",
    "#sub.to_csv('submission.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed84db38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-01T03:20:38.322154Z",
     "iopub.status.busy": "2021-11-01T03:20:38.321212Z",
     "iopub.status.idle": "2021-11-01T03:20:49.894633Z",
     "shell.execute_reply": "2021-11-01T03:20:49.894120Z",
     "shell.execute_reply.started": "2021-10-31T18:46:13.067246Z"
    },
    "papermill": {
     "duration": 36.030004,
     "end_time": "2021-11-01T03:20:49.894790",
     "exception": false,
     "start_time": "2021-11-01T03:20:13.864786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ss = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\n",
    "\n",
    "ss['pressure'] = np.median(np.vstack(test_preds),axis=0)\n",
    "ss[\"pressure\"] =\\\n",
    "    np.round( (ss.pressure - PRESSURE_MIN)/PRESSURE_STEP ) * PRESSURE_STEP + PRESSURE_MIN\n",
    "ss.pressure = np.clip(ss.pressure, PRESSURE_MIN, PRESSURE_MAX)\n",
    "ss.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b5b3a7",
   "metadata": {
    "papermill": {
     "duration": 24.559574,
     "end_time": "2021-11-01T03:21:39.301975",
     "exception": false,
     "start_time": "2021-11-01T03:21:14.742401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15930.83322,
   "end_time": "2021-11-01T03:22:07.501753",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-10-31T22:56:36.668533",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
